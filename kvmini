#!/usr/bin/env python3
"""
kvmini: Unified CLI for KServe vLLM Mini benchmarking suite

Commands:
  deploy    Deploy inference service to Kubernetes
  bench     Run complete benchmark (deploy → load-test → analyze → cost → report)
  sweep     Run parameter sweeps (traffic patterns, scaling configs)
  report    Generate reports from existing run data
  bundle    Package run artifacts for distribution
  gate      Validate runs against SLO budgets
  compare   Compare baseline vs candidate runs
  fairness  Run dual-tenant fairness + backpressure harness
"""

import os
import sys
import subprocess
import argparse
import time
from typing import List, Optional
from pathlib import Path

# Add current directory to path to import local modules
sys.path.insert(0, str(Path(__file__).parent))

SCRIPT_DIR = Path(__file__).parent


def run_cmd(cmd: List[str], **kwargs) -> subprocess.CompletedProcess:
    """Run command with error handling"""
    print(f"→ {' '.join(cmd)}")
    return subprocess.run(cmd, check=True, **kwargs)


class DeployCommand:
    """Deploy inference service"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--namespace", required=True, help="Kubernetes namespace")
        parser.add_argument("--service", required=True, help="Service name")
        parser.add_argument("--model-uri", required=True, help="S3 model URI")
        parser.add_argument("--runtime", default="vllm", help="KServe runtime")
        parser.add_argument("--gpu-limit", type=int, default=1, help="GPU limit")
        parser.add_argument("--min-replicas", type=int, default=0, help="Min replicas")
        parser.add_argument("--max-replicas", type=int, default=1, help="Max replicas")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        cmd = [
            str(SCRIPT_DIR / "deploy.sh"),
            "--namespace", args.namespace,
            "--service", args.service,
            "--model-uri", args.model_uri,
            "--runtime", args.runtime,
            "--gpu-limit", str(args.gpu_limit),
            "--min-replicas", str(args.min_replicas),
            "--max-replicas", str(args.max_replicas)
        ]
        run_cmd(cmd)
        return 0


class BenchCommand:
    """Run complete benchmark"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--namespace", required=True, help="Kubernetes namespace")
        parser.add_argument("--service", required=True, help="Service name")
        parser.add_argument("--model", required=True, help="Model name for requests")
        parser.add_argument("--requests", type=int, default=100, help="Number of requests")
        parser.add_argument("--concurrency", type=int, default=10, help="Concurrent requests")
        parser.add_argument("--max-tokens", type=int, default=64, help="Max tokens per request")
        parser.add_argument("--prom-url", help="Prometheus URL for metrics")
        parser.add_argument("--bundle", action="store_true", help="Bundle artifacts after run")
        parser.add_argument("--run-id", help="Custom run ID (default: timestamp)")
        parser.add_argument("--loadtest-args", help="Extra args to pass to load-test (quoted)")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        cmd = [
            str(SCRIPT_DIR / "bench.sh"),
            "--namespace", args.namespace,
            "--service", args.service,
            "--model", args.model,
            "--requests", str(args.requests),
            "--concurrency", str(args.concurrency),
            "--max-tokens", str(args.max_tokens)
        ]
        
        if args.prom_url:
            cmd.extend(["--prom-url", args.prom_url])
        if args.run_id:
            cmd.extend(["--run-id", args.run_id])
        if args.bundle:
            cmd.append("--bundle")
        if args.loadtest_args:
            cmd.extend(["--loadtest-args", args.loadtest_args])
            
        run_cmd(cmd)
        return 0


class SweepCommand:
    """Run parameter sweeps"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--namespace", required=True, help="Kubernetes namespace")
        parser.add_argument("--service", required=True, help="Service name")
        parser.add_argument("--model", required=True, help="Model name")
        parser.add_argument("--sweep-type", choices=["autoscale", "traffic", "mig", "quant"], 
                          default="traffic", help="Type of sweep")
        parser.add_argument("--prom-url", help="Prometheus URL")
        parser.add_argument("--output-dir", default="sweeps", help="Output directory")
        parser.add_argument("--config", help="Config file for sweep (quant)")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        if args.sweep_type == "autoscale":
            script = "sweeps/autoscale-sweep.sh"
        elif args.sweep_type == "mig":
            script = "sweeps/mig-sweep.sh"  
        elif args.sweep_type == "quant":
            # Run Python quantization/decoding sweep engine
            cmd = [
                sys.executable, str(SCRIPT_DIR / "sweeps" / "quantization_sweep.py"),
                "--output-dir", args.output_dir + "/quantization"
            ]
            if args.config:
                cmd.extend(["--config", args.config])
            run_cmd(cmd)
            return 0
        else:
            script = "grid-sweep.sh"
            
        cmd = [
            str(SCRIPT_DIR / script),
            "--namespace", args.namespace,
            "--service", args.service,
            "--model", args.model,
            "--output-dir", args.output_dir
        ]
        
        if args.prom_url:
            cmd.extend(["--prom-url", args.prom_url])
            
        run_cmd(cmd)
        return 0


class ReportCommand:
    """Generate reports from run data"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--run-dir", required=True, help="Run directory or bundle")
        parser.add_argument("--output", help="Output HTML file")
        parser.add_argument("--format", choices=["html", "json"], default="html")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        # Expect results.json in run-dir
        results_json = Path(args.run_dir) / "results.json"
        cmd = ["python3", str(SCRIPT_DIR / "report_generator.py"), "--input", str(results_json)]
        
        if args.output:
            cmd.extend(["--output", args.output])
            
        run_cmd(cmd)
        return 0


class BundleCommand:
    """Package run artifacts"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--run-dir", required=True, help="Run directory to bundle")
        parser.add_argument("--output", help="Output tarball path")
        parser.add_argument("--sign", action="store_true", help="Sign the bundle")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        cmd = [str(SCRIPT_DIR / "tools" / "bundle_run.sh"), args.run_dir]
        
        if args.output:
            cmd.extend(["--output", args.output])
        if args.sign:
            cmd.append("--sign")
            
        run_cmd(cmd)
        return 0


class GateCommand:
    """Validate runs against SLO budgets"""
    
    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--results", required=True, help="Results JSON file")
        parser.add_argument("--slo", required=True, help="SLO configuration file")
        parser.add_argument("--energy", help="Energy JSON file")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        cmd = ["python3", str(SCRIPT_DIR / "tools" / "gate.py"), 
               "--results", args.results, "--slo", args.slo]
        
        if args.energy:
            cmd.extend(["--energy", args.energy])
            
        result = subprocess.run(cmd)
        return result.returncode


class CompareCommand:
    """Compare baseline vs candidate runs"""
    
    @staticmethod  
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--baseline", required=True, help="Baseline run dir/bundle")
        parser.add_argument("--candidate", required=True, help="Candidate run dir/bundle")
        parser.add_argument("--output", required=True, help="Output HTML report")
        parser.add_argument("--json", help="JSON output path")
    
    @staticmethod
    def run(args: argparse.Namespace) -> int:
        cmd = ["python3", str(SCRIPT_DIR / "tools" / "canary_compare.py"),
               "--baseline", args.baseline,
               "--candidate", args.candidate, 
               "--out", args.output]
        
        if args.json:
            cmd.extend(["--json", args.json])
            
        result = subprocess.run(cmd)
        return result.returncode


class FairnessCommand:
    """Run dual-tenant fairness + backpressure harness"""

    @staticmethod
    def add_args(parser: argparse.ArgumentParser):
        parser.add_argument("--namespace", required=True, help="Kubernetes namespace")
        parser.add_argument("--service", required=True, help="Service name")
        parser.add_argument("--model", required=True, help="Model name")
        parser.add_argument("--tenant-a-requests", type=int, default=200)
        parser.add_argument("--tenant-b-requests", type=int, default=200)
        parser.add_argument("--tenant-a-concurrency", type=int, default=10)
        parser.add_argument("--tenant-b-concurrency", type=int, default=10)
        parser.add_argument("--p95-budget-ms", type=float, default=None)
        parser.add_argument("--api-key", default=None)
        parser.add_argument("--run-id", help="Custom run ID (default: timestamp)")
        parser.add_argument("--insecure", action="store_true")
        parser.add_argument("--slo", help="SLO JSON with fairness section")

    @staticmethod
    def run(args: argparse.Namespace) -> int:
        # Discover URL
        result = subprocess.run([
            "kubectl", "get", "inferenceservice", args.service, "-n", args.namespace,
            "-o", "jsonpath={.status.url}"
        ], capture_output=True, text=True)
        url = result.stdout.strip()
        if not url:
            print("ERROR: Could not discover service URL", file=sys.stderr)
            return 2

        run_id = args.run_id or time.strftime('%Y-%m-%d_%H-%M-%S')
        run_dir = Path("runs") / f"fairness_{run_id}"
        run_dir.mkdir(parents=True, exist_ok=True)

        cmd = [
            sys.executable, str(SCRIPT_DIR / "scripts" / "fairness_dual_tenant.py"),
            "--url", url,
            "--model", args.model,
            "--tenant-a-requests", str(args.tenant_a_requests),
            "--tenant-b-requests", str(args.tenant_b_requests),
            "--tenant-a-concurrency", str(args.tenant_a_concurrency),
            "--tenant-b-concurrency", str(args.tenant_b_concurrency),
            "--run-dir", str(run_dir)
        ]
        if args.p95_budget_ms:
            cmd.extend(["--p95-budget-ms", str(args.p95_budget_ms)])
        if args.api_key:
            cmd.extend(["--api-key", args.api_key])
        if args.insecure:
            cmd.append("--insecure")
        if args.slo:
            cmd.extend(["--slo", args.slo])

        return run_cmd(cmd).returncode


def main():
    parser = argparse.ArgumentParser(
        description="KServe vLLM Mini unified CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # Deploy command
    deploy_parser = subparsers.add_parser("deploy", help="Deploy inference service")
    DeployCommand.add_args(deploy_parser)
    
    # Bench command  
    bench_parser = subparsers.add_parser("bench", help="Run complete benchmark")
    BenchCommand.add_args(bench_parser)
    
    # Sweep command
    sweep_parser = subparsers.add_parser("sweep", help="Run parameter sweeps")
    SweepCommand.add_args(sweep_parser)
    
    # Report command
    report_parser = subparsers.add_parser("report", help="Generate reports")
    ReportCommand.add_args(report_parser)
    
    # Bundle command
    bundle_parser = subparsers.add_parser("bundle", help="Package run artifacts")
    BundleCommand.add_args(bundle_parser)
    
    # Gate command
    gate_parser = subparsers.add_parser("gate", help="Validate SLOs")
    GateCommand.add_args(gate_parser)
    
    # Compare command
    compare_parser = subparsers.add_parser("compare", help="Compare runs")
    CompareCommand.add_args(compare_parser)
    
    # Fairness command
    fairness_parser = subparsers.add_parser("fairness", help="Dual-tenant fairness with backpressure")
    FairnessCommand.add_args(fairness_parser)
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    # Route to appropriate command handler
    commands = {
        "deploy": DeployCommand,
        "bench": BenchCommand,
        "sweep": SweepCommand,
        "report": ReportCommand,
        "bundle": BundleCommand,
        "gate": GateCommand,
        "compare": CompareCommand,
        "fairness": FairnessCommand,
    }
    
    return commands[args.command].run(args)


if __name__ == "__main__":
    sys.exit(main())
